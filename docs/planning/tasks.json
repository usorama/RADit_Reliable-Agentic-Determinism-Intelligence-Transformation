[
  {
    "id": "CORE-001",
    "type": "setup",
    "priority": "P0",
    "phase": 0,
    "description": "Initialize Monorepo Structure",
    "command": "mkdir -p packages/daw-agents packages/daw-frontend packages/daw-protocol docs/scrum docs/stories docs/test_strategy",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-agents"
    },
    "status": "completed",
    "completed_at": "2025-12-30T16:42:00Z"
  },
  {
    "id": "INFRA-001",
    "type": "setup",
    "priority": "P0",
    "phase": 0,
    "description": "Configure MCP Servers (Git, FS, Postgres) and Docker Infrastructure",
    "dependencies": [
      "CORE-001"
    ],
    "command": "echo 'Create docker-compose.yml for mcp-servers, neo4j, and redis'",
    "context_files": [
      "docker-compose.yml"
    ],
    "instruction": "Define services for `git-mcp`, `filesystem-mcp`, `postgres-mcp`, `neo4j`, and `redis` with proper volume mounts and network isolation.",
    "verification": {
      "type": "file_exists",
      "path": "docker-compose.yml"
    },
    "status": "completed",
    "completed_at": "2025-12-30T11:19:07Z"
  },
  {
    "id": "INFRA-002",
    "type": "setup",
    "priority": "P0",
    "phase": 0,
    "description": "Configure Redis for Celery Broker and LangGraph Checkpoints",
    "dependencies": [
      "CORE-001"
    ],
    "context_files": [
      "docker-compose.yml",
      "packages/daw-agents/src/config/redis.py"
    ],
    "instruction": "Add Redis 7.x service to docker-compose.yml. Configure for dual use: (1) Celery message broker, (2) LangGraph checkpoint persistence. Set memory limits (maxmemory 256mb), persistence policy (RDB snapshots), and security (password auth). Create Python configuration module.",
    "verification": {
      "type": "test_pass",
      "command": "docker-compose up -d redis && python -c 'import redis; r=redis.Redis(); r.ping()'"
    },
    "status": "completed",
    "completed_at": "2025-12-30T17:00:00Z"
  },
  {
    "id": "PROMPT-GOV-001",
    "type": "setup",
    "priority": "P1",
    "phase": 0,
    "description": "Implement Prompt Template Governance Structure",
    "dependencies": [
      "CORE-001"
    ],
    "command": "mkdir -p packages/daw-agents/prompts/{planner,executor,validator,healer} tests/prompts/goldens",
    "instruction": "Establish prompt governance structure: (1) All prompts stored in packages/daw-agents/{agent}/prompts/, (2) Prompts versioned with semantic versioning (e.g., prd_generator_v1.0.yaml), (3) Each prompt includes version, name, persona, system_prompt, validation_checklist, and output_schema fields. Changes require PR review by designated 'Prompt Engineers'.",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-agents/prompts/planner"
    },
    "status": "completed",
    "completed_at": "2025-12-30T17:15:00Z"
  },
  {
    "id": "CORE-002",
    "type": "setup",
    "priority": "P0",
    "phase": 1,
    "description": "Initialize Python Backend (FastAPI + LangGraph)",
    "dependencies": [
      "CORE-001"
    ],
    "command": "cd packages/daw-agents && poetry init -n --name daw-agents --description 'Deterministic Agentic Workbench Backend' && poetry add fastapi uvicorn langgraph langchain-openai litellm",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-agents/pyproject.toml"
    },
    "status": "completed",
    "completed_at": "2025-12-30T11:21:59Z"
  },
  {
    "id": "FRONTEND-001",
    "type": "setup",
    "priority": "P0",
    "phase": 1,
    "description": "Initialize Next.js Frontend",
    "dependencies": [
      "CORE-001"
    ],
    "command": "npx create-next-app@latest packages/daw-frontend --typescript --tailwind --eslint",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-frontend/package.json"
    },
    "status": "completed",
    "completed_at": "2025-12-30T11:20:10Z"
  },
  {
    "id": "AUTH-001",
    "type": "setup",
    "priority": "P0",
    "phase": 1,
    "description": "Initialize Clerk Authentication",
    "dependencies": [
      "CORE-001"
    ],
    "command": "echo 'Create Clerk application and get API Keys'",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-agents/.env"
    },
    "status": "completed",
    "completed_at": "2025-12-30T17:30:00Z"
  },
  {
    "id": "DB-001",
    "type": "code",
    "priority": "P0",
    "phase": 1,
    "description": "Implement Neo4j Connector",
    "dependencies": [
      "CORE-002"
    ],
    "context_files": [
      "packages/daw-agents/src/memory/neo4j.py"
    ],
    "instruction": "Create a singleton class to manage Neo4j connections and simple graph read/write queries.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/memory/test_neo4j.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T18:30:00Z",
    "completed_at": "2025-12-30T19:15:00Z"
  },
  {
    "id": "CORE-003",
    "type": "code",
    "priority": "P0",
    "phase": 1,
    "description": "Implement MCP Client Interface (Protocol Layer)",
    "dependencies": [
      "CORE-002"
    ],
    "context_files": [
      "packages/daw-agents/src/mcp/client.py"
    ],
    "instruction": "Create a generic MCP client wrapper that can discover tools from a connected MCP server. Must support JSON-RPC.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/mcp/test_mcp_client.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T19:00:00Z",
    "completed_at": "2025-12-30T19:30:00Z"
  },
  {
    "id": "MODEL-001",
    "type": "code",
    "priority": "P0",
    "phase": 1,
    "description": "Implement Model Layer Abstraction with Router Mode",
    "dependencies": [
      "CORE-002"
    ],
    "context_files": [
      "packages/daw-agents/src/models/router.py",
      "packages/daw-agents/src/models/providers.py"
    ],
    "instruction": "Implement model abstraction layer using LiteLLM. Create Router Mode to select models based on task complexity: o1/opus for planning tasks, sonnet/haiku for coding, gpt-4o for validation (to ensure different model from executor). Include model configuration, fallback logic, and cost tracking integration with Helicone. See FR-01.1 in PRD.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/models/test_router.py"
    },
    "status": "completed",
    "completed_at": "2025-12-30T19:30:00Z"
  },
  {
    "id": "AUTH-002",
    "type": "code",
    "priority": "P0",
    "phase": 2,
    "description": "Implement FastAPI Middleware for Clerk",
    "dependencies": [
      "CORE-002",
      "AUTH-001"
    ],
    "context_files": [
      "packages/daw-agents/src/auth/clerk.py"
    ],
    "instruction": "Verify JWT tokens from incoming requests against Clerk JWKS.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/test_auth.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T18:00:00Z",
    "completed_at": "2025-12-30T19:45:00Z"
  },
  {
    "id": "MCP-SEC-001",
    "type": "code",
    "priority": "P1",
    "phase": 2,
    "description": "Implement MCP Gateway Authorization (OAuth 2.1 + RFC 8707)",
    "dependencies": [
      "CORE-003",
      "AUTH-002"
    ],
    "context_files": [
      "packages/daw-agents/src/mcp/gateway.py",
      "packages/daw-agents/src/mcp/auth.py"
    ],
    "instruction": "Harden the MCP gateway with OAuth 2.1 and RFC 8707 Resource Indicators: (1) Per-agent scoped tokens (e.g., database agent: SELECT only, no DDL), (2) Token TTL: 15 minutes for automated sessions, 1 hour for interactive, (3) Implement token refresh and revocation mechanisms, (4) Validate all tool calls against agent's granted scopes. See FR-01.3.1 in PRD.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/mcp/test_gateway_auth.py"
    },
    "status": "completed",
    "started_at": "2025-12-31T00:30:00Z",
    "completed_at": "2025-12-31T01:00:00Z"
  },
  {
    "id": "MCP-SEC-002",
    "type": "code",
    "priority": "P1",
    "phase": 2,
    "description": "Implement RBAC for MCP Tools",
    "dependencies": [
      "MCP-SEC-001"
    ],
    "context_files": [
      "packages/daw-agents/src/mcp/rbac.py",
      "packages/daw-agents/src/mcp/policies.yaml"
    ],
    "instruction": "Implement fine-grained Role-Based Access Control for tools: Planner: search, read_file, query_db (SELECT) - No writes; Executor: read_file, write_file, git_commit - write_file scoped to project directory; Validator: run_tests, security_scan, lint - No file writes; Healer: read_file, write_file (patches only) - Requires human approval for production. Store policies in YAML configuration. See FR-01.3.2 in PRD.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/mcp/test_rbac.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T03:30:00Z",
    "completed_at": "2025-12-30T04:00:00Z"
  },
  {
    "id": "MCP-SEC-003",
    "type": "code",
    "priority": "P1",
    "phase": 2,
    "description": "Implement MCP Audit Logging",
    "dependencies": [
      "MCP-SEC-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/mcp/audit.py"
    ],
    "instruction": "Every tool call must be logged with: timestamp, agent_id, user_id, tool name, action, parameters, result status, response time. Implement hash-chaining for tamper resistance. Configure 7-year retention for SOC 2/ISO 27001 compliance. Integrate with observability stack (Helicone). See FR-01.3.3 in PRD.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/mcp/test_audit.py"
    },
    "status": "completed",
    "completed_at": "2025-12-30T19:30:00Z"
  },
  {
    "id": "MCP-SEC-004",
    "type": "code",
    "priority": "P1",
    "phase": 2,
    "description": "Implement Content Injection Prevention",
    "dependencies": [
      "MCP-SEC-001"
    ],
    "context_files": [
      "packages/daw-agents/src/mcp/shields.py"
    ],
    "instruction": "Implement AI Prompt Shields for tool output sanitization. Create JSON schema validation for all tool inputs/outputs. Block dangerous command patterns: DROP, DELETE, rm -rf, sudo, and similar destructive operations. Integrate with the gateway to reject malicious requests before execution. See FR-01.3.4 in PRD.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/mcp/test_shields.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T15:00:00Z",
    "completed_at": "2025-12-30T15:30:00Z"
  },
  {
    "id": "PROMPT-GOV-002",
    "type": "code",
    "priority": "P1",
    "phase": 2,
    "description": "Implement Prompt Regression Testing Harness",
    "dependencies": [
      "PROMPT-GOV-001",
      "CORE-002"
    ],
    "context_files": [
      "packages/daw-agents/src/testing/prompt_harness.py",
      "tests/prompts/conftest.py"
    ],
    "instruction": "Create a prompt testing harness that: (1) Stores golden input/output pairs in tests/prompts/goldens/, (2) Runs prompt regression tests on every prompt file change in CI, (3) Uses semantic similarity scoring against golden outputs (configurable threshold), (4) Performs automated JSON schema validation for structured outputs, (5) Reports prompt drift/degradation metrics. Integrate with pytest for CI execution.",
    "verification": {
      "tests_pass": true,
      "lint_pass": true,
      "coverage_met": true,
      "integration_verified": true
    },
    "status": "completed",
    "started_at": "2025-12-30T21:00:00Z",
    "completed_at": "2025-12-30T21:45:00Z"
  },
  {
    "id": "CORE-004",
    "type": "code",
    "priority": "P0",
    "phase": 3,
    "description": "Implement E2B Sandbox Wrapper (Security Layer)",
    "dependencies": [
      "CORE-002"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/sandbox/e2b.py"
    ],
    "instruction": "Create a wrapper around E2B SDK. Must enforce strict timeout, CPU/RAM limits, and network allowlist capabilities. Ensure sandbox cleanup on completion/error.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/sandbox/test_e2b.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T20:00:00Z",
    "completed_at": "2025-12-30T20:45:00Z"
  },
  {
    "id": "CORE-005",
    "type": "code",
    "priority": "P0",
    "phase": 3,
    "description": "Implement 'Red-Green-Refactor' Enforcement Logic",
    "dependencies": [
      "CORE-002"
    ],
    "context_files": [
      "packages/daw-agents/src/tdd/guard.py",
      "packages/daw-agents/src/tdd/exceptions.py"
    ],
    "instruction": "Create a logic module that checks for the existence of a failing test file before allowing 'Implementation' tools to be called. Must block writes to src/ until tests/ file exists and fails.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/tdd/test_guard.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T20:00:00Z",
    "completed_at": "2025-12-30T20:30:00Z"
  },
  {
    "id": "CORE-006",
    "type": "code",
    "priority": "P0",
    "phase": 3,
    "description": "Implement Context Compaction Logic",
    "dependencies": [
      "CORE-002",
      "DB-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/context/compaction.py"
    ],
    "instruction": "Create a module that summarizes conversation history and relevant graph nodes into a concise 'System Prompt' string. Must produce < 4000 tokens from 1000+ message history.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/context/test_compaction.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T21:30:00Z",
    "completed_at": "2025-12-30T22:15:00Z"
  },
  {
    "id": "OPS-001",
    "type": "code",
    "priority": "P0",
    "phase": 3,
    "description": "Implement Helicone Observability Proxy",
    "dependencies": [
      "CORE-002"
    ],
    "context_files": [
      "packages/daw-agents/src/ops/helicone.py"
    ],
    "instruction": "Wrap OpenAI/LiteLLM client calls to route through Helicone proxy for cost tracking. Attach request metadata (user_id, project_id, agent_type). Enable caching with configurable TTL.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/ops/test_helicone.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T20:00:00Z",
    "completed_at": "2025-12-30T20:30:00Z"
  },
  {
    "id": "PLANNER-001",
    "type": "code",
    "priority": "P1",
    "phase": 4,
    "description": "Implement 'Taskmaster' Agent Workflow",
    "dependencies": [
      "CORE-002",
      "DB-001",
      "CORE-003",
      "MODEL-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/agents/planner/taskmaster.py"
    ],
    "instruction": "Implement LangGraph state machine. States: [Interview, Roundtable, GeneratePRD]. Configurable personas. Use MODEL-001 router for model selection. Persist conversation to Neo4j.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/planner/test_taskmaster.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T20:45:00Z",
    "completed_at": "2025-12-30T21:30:00Z"
  },
  {
    "id": "PLANNER-002",
    "type": "code",
    "priority": "P1",
    "phase": 4,
    "description": "Implement 'Roundtable' Personas",
    "dependencies": [
      "PLANNER-001"
    ],
    "context_files": [
      "packages/daw-agents/src/agents/planner/personas.py"
    ],
    "instruction": "Define prompts for CTO, UX, and Security synthetic personas to critique concepts. Each persona provides distinct critique perspective.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/planner/test_personas.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T23:00:00Z",
    "completed_at": "2025-12-30T23:45:00Z"
  },
  {
    "id": "COMPLEXITY-001",
    "type": "code",
    "priority": "P1",
    "phase": 4,
    "description": "Implement Complexity Analysis Engine",
    "dependencies": [
      "PLANNER-001",
      "CORE-003"
    ],
    "context_files": [
      "packages/daw-agents/src/agents/planner/complexity_analyzer.py",
      "packages/daw-agents/src/schemas/complexity_analysis.py"
    ],
    "instruction": "Before any code is written, the system must analyze the PRD to produce complexity_analysis.json containing: (1) Feature-by-feature cognitive load scores (1-10), (2) Dependency graph with risk ratings (low/medium/high/critical), (3) Recommended model tier per task (planning: o1/opus, coding: sonnet/haiku), (4) Architectural bottleneck warnings and mitigation strategies. The analysis MUST complete successfully before task generation proceeds. Integrate with FR-02.4 Task Decomposition to inform task sizing in tasks.json. See FR-02.5 in PRD.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/planner/test_complexity_analyzer.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T23:30:00Z",
    "completed_at": "2025-12-31T00:00:00Z"
  },
  {
    "id": "TASK-DECOMP-001",
    "type": "code",
    "priority": "P0",
    "phase": 4,
    "description": "Implement Task Decomposition Agent (PRD -> tasks.json)",
    "dependencies": [
      "PLANNER-001",
      "COMPLEXITY-001"
    ],
    "context_files": [
      "packages/daw-agents/src/agents/planner/task_decomposer.py",
      "packages/daw-agents/src/schemas/task_schema.py"
    ],
    "instruction": "Implement agent that automatically parses prd.md into tasks.json format. Use complexity scores from COMPLEXITY-001 to inform task sizing. Generate task IDs, dependencies, context files, and verification criteria. Output must conform to existing tasks.json schema. Validate all tasks before emitting. See FR-02.4.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/planner/test_task_decomposer.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T13:48:12.154750Z",
    "completed_at": "2025-12-30T13:58:40.335192Z"
  },
  {
    "id": "PRD-OUTPUT-001",
    "type": "code",
    "priority": "P1",
    "phase": 4,
    "description": "Implement PRD Output Format and Validation",
    "dependencies": [
      "PLANNER-001"
    ],
    "context_files": [
      "packages/daw-agents/src/agents/planner/prd_generator.py",
      "packages/daw-agents/src/schemas/prd_schema.py"
    ],
    "instruction": "Define and implement PRD.md output format: (1) User Stories section with priority levels, (2) Tech Specs with architecture decisions, (3) Acceptance Criteria in testable format, (4) Non-functional requirements. Create JSON schema for PRD structure. Validate completeness before allowing Task Decomposition to proceed. See FR-02.3.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/planner/test_prd_generator.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T10:00:00Z",
    "completed_at": "2025-12-30T11:30:00Z"
  },
  {
    "id": "EXECUTOR-001",
    "type": "code",
    "priority": "P1",
    "phase": 5,
    "description": "Implement 'Developer' Agent Workflow",
    "dependencies": [
      "CORE-005",
      "CORE-004",
      "CORE-003",
      "MODEL-001"
    ],
    "context_files": [
      "packages/daw-agents/src/agents/developer/graph.py"
    ],
    "instruction": "Implement the Red-Green-Refactor loop graph. States: [WriteTest, RunTest, WriteCode, Refactor]. Use MODEL-001 router for model selection. Use MCP client (CORE-003) for tool calls.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/developer/test_graph.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T22:30:00Z",
    "completed_at": "2025-12-30T23:15:00Z"
  },
  {
    "id": "OPS-002",
    "type": "code",
    "priority": "P1",
    "phase": 5,
    "description": "Implement 'Healer' Agent Workflow",
    "dependencies": [
      "EXECUTOR-001",
      "DB-001",
      "CORE-003"
    ],
    "context_files": [
      "packages/daw-agents/src/agents/healer/graph.py"
    ],
    "instruction": "Implement a specialized graph that takes a failed ToolOutput, queries Neo4j knowledge graph for similar past errors, and suggests a fix. Store successful error resolutions for future RAG. Auto-retry up to 3 times.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/healer/test_graph.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T03:00:00Z",
    "completed_at": "2025-12-30T03:45:00Z"
  },
  {
    "id": "RULES-001",
    "type": "code",
    "priority": "P1",
    "phase": 5,
    "description": "Implement Rule Enforcement (.cursorrules / Linter Integration)",
    "dependencies": [
      "EXECUTOR-001"
    ],
    "context_files": [
      "packages/daw-agents/src/workflow/rule_enforcer.py",
      ".cursorrules"
    ],
    "instruction": "Implement coding style enforcement in Executor workflow. Parse .cursorrules file for style constraints. Integrate with Ruff (Python) and ESLint (TypeScript) for automatic linting. Code must pass all lint checks before being accepted in Green phase. Auto-fix minor issues where possible. See FR-03.4.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/workflow/test_rule_enforcer.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T12:00:00Z",
    "completed_at": "2025-12-30T13:57:47Z"
  },
  {
    "id": "VALIDATOR-001",
    "type": "code",
    "priority": "P0",
    "phase": 6,
    "description": "Implement Validator Agent (DISTINCT from Sandbox)",
    "dependencies": [
      "CORE-002",
      "MODEL-001",
      "CORE-003"
    ],
    "context_files": [
      "packages/daw-agents/src/agents/validator/agent.py",
      "packages/daw-agents/src/agents/validator/nodes.py",
      "packages/daw-agents/src/agents/validator/models.py",
      "packages/daw-agents/src/agents/validator/state.py"
    ],
    "instruction": "Implement a Validator Agent as a LangGraph workflow DISTINCT from the sandbox execution environment. The Validator Agent must: (1) Run on a DIFFERENT model than Executor via MODEL-001 router (e.g., if Executor uses Claude, Validator uses GPT-4o), (2) Execute test suites and interpret results intelligently, (3) Run SAST security scans via tool integration, (4) Perform SCA vulnerability scanning, (5) Validate against organizational policies, (6) Generate actionable improvement suggestions (not just pass/fail), (7) Implement retry logic routing fixable failures back to Executor (max 3 retries), (8) Escalate critical/unfixable issues to human reviewers. States: [run_tests, security_scan, policy_check, generate_report, route_decision]. CRITICAL: Validator is architecturally SEPARATE from Sandbox (CORE-004). See FR-04.2 in PRD and Section 6 in Architecture.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/validator/test_validator.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T20:00:00Z",
    "completed_at": "2025-12-30T20:30:00Z"
  },
  {
    "id": "VALIDATOR-002",
    "type": "code",
    "priority": "P0",
    "phase": 6,
    "description": "Implement Multi-Model Validation Ensemble",
    "dependencies": [
      "VALIDATOR-001"
    ],
    "context_files": [
      "packages/daw-agents/src/agents/validator/ensemble.py"
    ],
    "instruction": "Implement ensemble validation using 2+ models for critical validations. Create a voting/consensus mechanism where multiple models must agree on pass/fail decisions for high-stakes validations. Configure which validations require ensemble (e.g., security-critical, production deployments).",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/validator/test_ensemble.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T22:30:00Z",
    "completed_at": "2025-12-30T23:00:00Z"
  },
  {
    "id": "POLICY-001",
    "type": "code",
    "priority": "P0",
    "phase": 6,
    "description": "Implement Policy-as-Code Deployment Gates",
    "dependencies": [
      "VALIDATOR-001"
    ],
    "context_files": [
      "packages/daw-agents/src/deploy/gates.py",
      "packages/daw-agents/src/deploy/policies.yaml",
      ".github/workflows/deploy.yml"
    ],
    "instruction": "Implement codified deployment policies enforced automatically. Gate 1 (Code Quality - BLOCKING): Test coverage >= 80% new code, >= 70% total; TypeScript strict mode enabled; 0 linting errors. Gate 2 (Security - BLOCKING): 0 SAST critical findings; 0 SCA critical CVEs; 0 secrets detected. Gate 3 (Performance - WARNING): API p95 < 500ms; Bundle size increase < 10%. Gate 4 (UAT - BLOCKING for prod): All P0 user journeys pass; Visual regression < 0.1%. See Architecture section 05_deployment.md.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/deploy/test_gates.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T03:30:00Z",
    "completed_at": "2025-12-30T04:00:00Z"
  },
  {
    "id": "POLICY-002",
    "type": "code",
    "priority": "P0",
    "phase": 6,
    "description": "Implement Zero-Copy Fork for Database Migrations",
    "dependencies": [
      "DB-001",
      "POLICY-001"
    ],
    "context_files": [
      "packages/daw-agents/src/deploy/migration.py",
      ".github/workflows/migration.yml"
    ],
    "instruction": "Implement safe database migration pattern: (1) Create zero-copy fork of production database (instant, no data duplication), (2) Apply migration to fork, (3) Run full validation suite on fork, (4) If all tests pass, apply migration to production, (5) If any test fails, discard fork with zero production impact. Integrate with CI/CD pipeline. See Architecture section 05_deployment.md.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/deploy/test_migration.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T22:00:00Z",
    "completed_at": "2025-12-30T15:23:41Z"
  },
  {
    "id": "API-001",
    "type": "code",
    "priority": "P1",
    "phase": 7,
    "description": "Define FastAPI Route Endpoints",
    "dependencies": [
      "CORE-002",
      "AUTH-002"
    ],
    "context_files": [
      "packages/daw-agents/src/api/routes.py",
      "packages/daw-agents/src/api/schemas.py"
    ],
    "instruction": "Define FastAPI routes: POST /api/chat (send message to Planner), GET /api/workflow/{id} (get workflow status), POST /api/workflow/{id}/approve (human approval), DELETE /api/workflow/{id} (cancel workflow), WebSocket /ws/trace/{id} (real-time updates). All routes protected by Clerk auth middleware. Include OpenAPI documentation.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/api/test_routes.py"
    },
    "status": "completed",
    "completed_at": "2025-12-30T14:00:00Z"
  },
  {
    "id": "STREAMING-001",
    "type": "code",
    "priority": "P1",
    "phase": 7,
    "description": "Implement WebSocket Streaming Infrastructure",
    "dependencies": [
      "CORE-002",
      "FRONTEND-001"
    ],
    "context_files": [
      "packages/daw-agents/src/api/websocket.py",
      "packages/daw-frontend/src/hooks/useAgentStream.ts"
    ],
    "instruction": "Implement WebSocket infrastructure for real-time agent updates: (1) FastAPI WebSocket endpoint with auth, (2) LangGraph callback to emit state transitions, (3) Frontend hook to connect and receive updates, (4) Reconnection logic with exponential backoff. Support multiple concurrent clients per workflow.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/api/test_websocket.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T12:00:00Z",
    "completed_at": "2025-12-30T12:30:00Z"
  },
  {
    "id": "FRONTEND-AUTH-001",
    "type": "code",
    "priority": "P1",
    "phase": 7,
    "description": "Integrate Clerk React SDK in Frontend",
    "dependencies": [
      "FRONTEND-001",
      "AUTH-001"
    ],
    "context_files": [
      "packages/daw-frontend/src/providers/AuthProvider.tsx",
      "packages/daw-frontend/src/components/auth/SignIn.tsx",
      "packages/daw-frontend/src/middleware.ts"
    ],
    "instruction": "Integrate Clerk React SDK: (1) Create ClerkProvider wrapper, (2) Implement SignIn/SignUp components, (3) Add protected route middleware, (4) Create user session hook, (5) Display user info in header. Use @clerk/nextjs package.",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-frontend/src/providers/AuthProvider.tsx"
    },
    "status": "completed",
    "started_at": "2025-12-30T22:00:00Z",
    "completed_at": "2025-12-30T22:30:00Z"
  },
  {
    "id": "FRONTEND-002",
    "type": "code",
    "priority": "P1",
    "phase": 7,
    "description": "Implement Agent Trace UI",
    "dependencies": [
      "FRONTEND-001",
      "STREAMING-001"
    ],
    "context_files": [
      "packages/daw-frontend/src/components/AgentTrace.tsx"
    ],
    "instruction": "Create a React component to visualize the LangGraph state stream via WebSocket. Live 'thought bubble' shows agent reasoning in real-time. Expandable/collapsible trace sections. Trace persisted for replay.",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-frontend/src/components/AgentTrace.tsx"
    },
    "status": "completed",
    "started_at": "2025-12-30T23:00:00Z",
    "completed_at": "2025-12-30T23:30:00Z"
  },
  {
    "id": "FRONTEND-003",
    "type": "code",
    "priority": "P0",
    "phase": 7,
    "description": "Implement Chat Interface for Planner Interaction",
    "dependencies": [
      "FRONTEND-001",
      "STREAMING-001"
    ],
    "context_files": [
      "packages/daw-frontend/src/components/ChatInterface.tsx",
      "packages/daw-frontend/src/hooks/useChat.ts"
    ],
    "instruction": "Create chat interface component allowing users to interact with Planner agent. Support: (1) Markdown rendering with syntax highlighting, (2) Code block copy buttons, (3) File attachment uploads, (4) Typing indicators, (5) Message history. Connect to backend via WebSocket for real-time streaming responses. This is the primary user entry point for the system.",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-frontend/src/components/ChatInterface.tsx"
    },
    "status": "completed",
    "started_at": "2025-12-30T20:45:00Z",
    "completed_at": "2025-12-30T21:00:00Z"
  },
  {
    "id": "INFRA-003",
    "type": "code",
    "priority": "P1",
    "phase": 7,
    "description": "Configure Celery Workers for Background Processing",
    "dependencies": [
      "INFRA-002"
    ],
    "context_files": [
      "packages/daw-agents/src/workers/celery_app.py",
      "packages/daw-agents/src/workers/tasks.py"
    ],
    "instruction": "Configure Celery 5.x for background agent task processing: (1) Define Celery app with Redis broker, (2) Create task queue definitions (planner, executor, validator), (3) Set concurrency and prefetch settings, (4) Implement retry policies with exponential backoff, (5) Add task result backend (Redis).",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/workers/test_celery.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T21:00:00Z",
    "completed_at": "2025-12-30T21:45:00Z"
  },
  {
    "id": "EVAL-001",
    "type": "setup",
    "priority": "P0",
    "phase": 7,
    "description": "Establish Eval Protocol Golden Benchmark Suite",
    "dependencies": [
      "PLANNER-001",
      "EXECUTOR-001"
    ],
    "command": "mkdir -p eval/benchmarks/{calculator,todo_app,ecommerce_checkout} eval/goldens eval/results",
    "context_files": [
      "eval/README.md",
      "eval/benchmarks/index.json"
    ],
    "instruction": "Establish golden benchmark infrastructure: (1) Create 10-20 representative PRDs (Calculator, ToDo App, E-commerce Checkout, etc.), (2) Store expected outputs (tests, code, architecture) as golden references, (3) Define scoring rubrics for each benchmark, (4) Create benchmark index file with metadata. See test_strategy.md Section 4.",
    "verification": {
      "type": "file_exists",
      "path": "eval/benchmarks/index.json"
    },
    "status": "completed",
    "started_at": "2025-12-30T19:18:00Z",
    "completed_at": "2025-12-30T20:00:00Z"
  },
  {
    "id": "EVAL-002",
    "type": "code",
    "priority": "P0",
    "phase": 7,
    "description": "Implement Eval Harness with Performance Metrics",
    "dependencies": [
      "EVAL-001",
      "VALIDATOR-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/eval/harness.py",
      "packages/daw-agents/src/daw_agents/eval/metrics.py"
    ],
    "instruction": "Implement eval harness using DeepEval or Braintrust framework. Track metrics: pass@1 (first attempt success) >= 85% release blocking; Task Completion Rate >= 90% release blocking; pass^8 (8-trial consistency) >= 60% warning; Cost per Task < $0.50 avg advisory. Integrate with CI for nightly runs. Performance regression > 5% triggers alert. Store timestamped results in eval_results/. See test_strategy.md Section 4.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/eval/test_harness.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T22:00:00Z",
    "completed_at": "2025-12-30T23:00:00Z"
  },
  {
    "id": "EVAL-003",
    "type": "code",
    "priority": "P0",
    "phase": 7,
    "description": "Implement Agent Similarity Scoring",
    "dependencies": [
      "EVAL-002"
    ],
    "context_files": [
      "packages/daw-agents/src/eval/similarity.py"
    ],
    "instruction": "Implement semantic similarity scoring for agent outputs against golden references. Agent must achieve >= 85% similarity score on golden PRDs. Use embedding-based comparison for textual outputs and AST comparison for code outputs. Report detailed breakdown of where outputs diverge.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/eval/test_similarity.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T23:45:00Z",
    "completed_at": "2025-12-31T00:30:00Z"
  },
  {
    "id": "UAT-001",
    "type": "code",
    "priority": "P1",
    "phase": 7,
    "description": "Implement UAT Agent with Playwright MCP",
    "dependencies": [
      "VALIDATOR-001",
      "FRONTEND-002",
      "CORE-003"
    ],
    "context_files": [
      "packages/daw-agents/src/agents/uat/graph.py",
      "packages/daw-agents/src/agents/uat/tools.py",
      "packages/daw-agents/src/agents/uat/personas.yaml"
    ],
    "instruction": "Implement UAT Agent using Playwright MCP for browser automation. The agent must: (1) Operate on accessibility snapshots (not screenshots) for determinism and speed, (2) Support cross-browser testing (Chromium, Firefox, WebKit), (3) Execute Gherkin scenarios (Given/When/Then) translated from PRD acceptance criteria, (4) Generate validation reports with screenshots, traces, and timing. See FR-06 in PRD.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/uat/test_graph.py"
    },
    "status": "completed",
    "started_at": "2025-12-31T00:00:00Z",
    "completed_at": "2025-12-31T00:45:00Z"
  },
  {
    "id": "UAT-002",
    "type": "code",
    "priority": "P1",
    "phase": 7,
    "description": "Implement Persona-Based UAT Testing",
    "dependencies": [
      "UAT-001"
    ],
    "context_files": [
      "packages/daw-agents/src/agents/uat/personas.yaml",
      "packages/daw-agents/src/agents/uat/persona_engine.py"
    ],
    "instruction": "Define and implement user personas in uat/personas.yaml: 'Power User' (Desktop, fast network, uses keyboard shortcuts), 'First-Time User' (Mobile, 3G network, help-seeking behavior), 'Accessibility User' (Screen reader, keyboard-only navigation). Each persona modifies how the UAT Agent interacts with the UI. See FR-06.2 in PRD.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/uat/test_personas.py"
    },
    "status": "completed",
    "started_at": "2025-12-31T01:00:00Z",
    "completed_at": "2025-12-31T01:30:00Z"
  },
  {
    "id": "UAT-003",
    "type": "code",
    "priority": "P1",
    "phase": 7,
    "description": "Implement Visual Regression Testing",
    "dependencies": [
      "UAT-001"
    ],
    "context_files": [
      "packages/daw-agents/src/agents/uat/visual_regression.py"
    ],
    "instruction": "Integrate AI-powered visual comparison (Applitools Eyes or equivalent). Threshold: < 0.1% pixel difference for critical UI components. Implement automatic baseline updates for approved intentional changes. Store baseline images with version control. See FR-06.4 in PRD.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/uat/test_visual_regression.py"
    },
    "status": "completed",
    "started_at": "2025-12-31T01:00:00Z",
    "completed_at": "2025-12-31T01:30:00Z"
  },
  {
    "id": "DRIFT-001",
    "type": "code",
    "priority": "P2",
    "phase": 8,
    "description": "Implement Drift Detection Metrics",
    "dependencies": [
      "OPS-001",
      "EXECUTOR-001"
    ],
    "context_files": [
      "packages/daw-agents/src/ops/drift_detector.py",
      "packages/daw-agents/src/ops/metrics.py"
    ],
    "instruction": "Implement drift detection monitoring: Tool Usage Frequency (+50% deviation = log warning), Reasoning Step Count (+100% increase = pause agent), Context Window Utilization (>90% = force compaction), Retry Rate (>3x baseline = escalate to human), Token Cost per Task (+200% increase = budget alert). Track baselines per task type. See FR-05.1 in PRD.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/ops/test_drift_detector.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T13:49:02.510363Z",
    "completed_at": "2025-12-30T13:55:55.579286Z"
  },
  {
    "id": "DRIFT-002",
    "type": "code",
    "priority": "P2",
    "phase": 8,
    "description": "Implement Drift Detection Alerting and Actions",
    "dependencies": [
      "DRIFT-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/ops/alerts.py",
      "packages/daw-agents/src/daw_agents/ops/actions.py"
    ],
    "instruction": "Implement drift response system: (1) Integrate with observability stack (Helicone, Datadog), (2) Slack/Linear notifications for drift detection, (3) Weekly drift report generation, (4) Action triggers: Mild drift = increase monitoring + log; Moderate drift = context compaction + model switch; Severe drift = pause agent + human intervention required. See FR-05.1 in PRD.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/ops/test_alerts.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T15:15:00.000Z",
    "completed_at": "2025-12-30T15:30:00.000Z"
  },
  {
    "id": "ORCHESTRATOR-001",
    "type": "code",
    "priority": "P0",
    "phase": 8,
    "description": "Implement Main Workflow Orchestrator (Planning -> Coding -> Testing)",
    "dependencies": [
      "MODEL-001",
      "PLANNER-001",
      "EXECUTOR-001",
      "VALIDATOR-001"
    ],
    "context_files": [
      "packages/daw-agents/src/workflow/orchestrator.py",
      "packages/daw-agents/src/workflow/states.py"
    ],
    "instruction": "Implement the main LangGraph workflow orchestrator that enforces the sequence: User Input -> Planner (Interview/Roundtable/GeneratePRD) -> Task Decomposition -> Executor (Red/Green/Refactor loop for each task) -> Validator -> Deployment Gates. Manage state transitions, checkpoints (Redis-backed via INFRA-002), and human-in-the-loop interrupts. This is the core workflow engine per FR-01.4. CRITICAL: This is the main entry point that coordinates all other agents.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/workflow/test_orchestrator.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T15:15:34.789341+00:00",
    "completed_at": "2025-12-30T15:24:23.458719+00:00"
  },
  {
    "id": "EVOLVE-001",
    "type": "code",
    "priority": "P1",
    "phase": 3,
    "description": "Implement Experience Logger for Self-Learning Foundation",
    "dependencies": [
      "CORE-006",
      "DB-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/evolution/experience_logger.py",
      "packages/daw-agents/src/daw_agents/evolution/schemas.py"
    ],
    "instruction": "Implement Experience Logger that stores successful task completions in Neo4j for future learning. Schema: Experience node with task_type, task_id, success, prompt_version, model_used, tokens_used, cost_usd, duration_ms, retries, timestamp. Create relationships: (:Experience)-[:USED_SKILL]->(:Skill) for code patterns, (:Experience)-[:PRODUCED]->(:Artifact) for outputs. Include: (1) ExperienceLogger class with log_success(), log_failure() methods, (2) query_similar_experiences() for RAG retrieval, (3) calculate_success_rate() per task type/model combination, (4) Neo4j Cypher queries for experience storage and retrieval. This is the foundation for self-learning capabilities per FR-07.1.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/evolution/test_experience_logger.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T12:00:00Z",
    "completed_at": "2025-12-30T14:00:00Z"
  },
  {
    "id": "EVOLVE-002",
    "type": "code",
    "priority": "P1",
    "phase": 8,
    "description": "Implement Reflection Hook for Post-Task Learning",
    "dependencies": [
      "DRIFT-001",
      "EVOLVE-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/evolution/reflection.py",
      "packages/daw-agents/src/daw_agents/ops/drift_detector.py"
    ],
    "instruction": "Implement Reflection Hook that triggers after successful task completion to extract learnings. Extends the Monitor Agent (DRIFT-001) with proactive reflection capabilities. Features: (1) ReflectionHook class that registers as LangGraph callback, (2) Triggers after task completion (not just on failure), (3) Uses LLM to analyze: 'What worked well?', 'What patterns should be remembered?', 'What could be improved?', (4) Stores insights as (:Insight) nodes linked to (:Experience), (5) Configurable reflection depth (quick/standard/deep), (6) Async execution to avoid blocking main workflow. This implements proactive learning per FR-07.2, transforming reactive Monitor-Diagnose-Heal into proactive reflection.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/evolution/test_reflection.py"
    },
    "status": "completed",
    "started_at": "2025-12-30T23:00:00Z",
    "completed_at": "2025-12-30T23:45:00Z"
  },
  {
    "id": "REFACTOR-001",
    "type": "refactor",
    "priority": "P1",
    "phase": 9,
    "description": "Create apps/ directory structure for monorepo",
    "dependencies": [],
    "context_files": [
      "docs/planning/architecture/sections/02_project_structure.md",
      "pnpm-workspace.yaml",
      "turbo.json"
    ],
    "instruction": "Create the apps/ directory structure per architecture docs: (1) Create apps/web/ and apps/server/ directories, (2) Update pnpm-workspace.yaml to include 'apps/*', (3) Update turbo.json pipeline if exists, (4) Verify monorepo tooling recognizes new structure with 'pnpm install'.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web"
    },
    "status": "completed",
    "completed_at": "2025-12-30T21:51:00Z"
  },
  {
    "id": "REFACTOR-002",
    "type": "refactor",
    "priority": "P1",
    "phase": 9,
    "description": "Migrate daw-frontend to apps/web/",
    "dependencies": [
      "REFACTOR-001"
    ],
    "context_files": [
      "packages/daw-frontend/package.json",
      "packages/daw-frontend/src/**/*",
      "packages/daw-frontend/tsconfig.json"
    ],
    "instruction": "Migrate frontend to apps/web/: (1) Move all files from packages/daw-frontend/ to apps/web/, (2) Update package.json name to '@daw/web', (3) Update all internal imports, (4) Update tsconfig paths if needed, (5) Run 'pnpm install' to verify, (6) Run 'pnpm dev' to verify frontend starts, (7) Run TypeScript check with 0 errors, (8) Delete empty packages/daw-frontend/ after verification.",
    "verification": {
      "type": "test_pass",
      "command": "cd apps/web && pnpm typecheck && pnpm build"
    },
    "status": "completed",
    "completed_at": "2025-12-30T21:58:00Z"
  },
  {
    "id": "REFACTOR-003",
    "type": "refactor",
    "priority": "P1",
    "phase": 9,
    "description": "Extract FastAPI server to apps/server/",
    "dependencies": [
      "REFACTOR-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/api/**/*",
      "packages/daw-agents/src/daw_agents/workers/**/*",
      "packages/daw-agents/src/daw_agents/auth/**/*"
    ],
    "instruction": "Extract server code to apps/server/: (1) Create apps/server/ with pyproject.toml, (2) Move API routes (api/), WebSocket handlers, middleware, Celery workers from daw-agents, (3) Server should import agents from packages/daw-agents as dependency, (4) Update all imports to reference daw-agents package, (5) Configure uvicorn entry point, (6) Test: 'uvicorn main:app' starts successfully, (7) Test: All API endpoints respond correctly.",
    "verification": {
      "type": "test_pass",
      "command": "cd apps/server && poetry install && pytest tests/"
    },
    "status": "completed",
    "completed_at": "2025-12-30T22:04:00Z"
  },
  {
    "id": "REFACTOR-004",
    "type": "refactor",
    "priority": "P1",
    "phase": 9,
    "description": "Refactor daw-agents to contain only agent definitions",
    "dependencies": [
      "REFACTOR-003"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/agents/**/*",
      "packages/daw-agents/src/daw_agents/schemas/**/*",
      "packages/daw-agents/prompts/**/*"
    ],
    "instruction": "Clean up daw-agents package: (1) After REFACTOR-003, remove API routes, Celery configs, middleware from daw-agents, (2) Keep ONLY: agents/ (planner, developer, validator, healer, uat), schemas/, prompts/, core utilities needed by agents, (3) Update __init__.py exports for clean agent library interface, (4) Package should be importable as library by apps/server, (5) Run all agent tests to verify nothing broken.",
    "verification": {
      "type": "test_pass",
      "command": "cd packages/daw-agents && poetry install && pytest tests/agents/"
    },
    "status": "completed",
    "completed_at": "2025-12-30T22:10:00Z"
  },
  {
    "id": "REFACTOR-005",
    "type": "refactor",
    "priority": "P2",
    "phase": 9,
    "description": "Create packages/daw-mcp/ for custom MCP servers",
    "dependencies": [
      "REFACTOR-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/mcp/**/*",
      "docs/planning/architecture/sections/02_project_structure.md"
    ],
    "instruction": "Create MCP servers package: (1) Create packages/daw-mcp/ with pyproject.toml, (2) Create subdirectories: git-mcp/, graph-memory/, (3) Move MCP-related code from daw-agents/mcp/ if exists, (4) Implement MCP server registration per protocol spec, (5) Each server should be independently runnable, (6) Update docker-compose.yml to include MCP server containers if needed.",
    "verification": {
      "type": "test_pass",
      "command": "cd packages/daw-mcp && poetry install && pytest tests/"
    },
    "status": "completed",
    "completed_at": "2025-12-30T22:02:00Z"
  },
  {
    "id": "REFACTOR-006",
    "type": "refactor",
    "priority": "P2",
    "phase": 9,
    "description": "Rename daw-shared to daw-protocol",
    "dependencies": [
      "REFACTOR-001"
    ],
    "context_files": [
      "packages/daw-protocol/**/*"
    ],
    "instruction": "Rename shared package: (1) Rename packages/daw-shared/ to packages/daw-protocol/, (2) Update package.json/pyproject.toml name to '@daw/protocol' or 'daw-protocol', (3) Search and replace all imports across entire codebase: 'daw-shared' -> 'daw-protocol', (4) Update pnpm-workspace.yaml if needed, (5) Run 'pnpm install' to verify, (6) Run full test suite to catch any missed imports.",
    "verification": {
      "type": "test_pass",
      "command": "pnpm install && pnpm test"
    },
    "status": "completed",
    "started_at": "2025-12-30T21:55:00Z",
    "completed_at": "2025-12-30T22:00:00Z"
  },
  {
    "id": "REFACTOR-007",
    "type": "test",
    "priority": "P0",
    "phase": 9,
    "description": "Comprehensive E2E validation post-refactor",
    "dependencies": [
      "REFACTOR-002",
      "REFACTOR-003",
      "REFACTOR-004",
      "REFACTOR-005",
      "REFACTOR-006"
    ],
    "context_files": [
      "docker-compose.yml",
      "apps/web/package.json",
      "apps/server/pyproject.toml"
    ],
    "instruction": "Full system validation: (1) Run all unit tests: pytest (Python), jest (TypeScript) - ALL MUST PASS, (2) Run integration tests, (3) Build Docker images: 'docker-compose build' succeeds, (4) Start full system: 'docker-compose up' - all services healthy, (5) Verify connectivity: frontend -> backend -> Neo4j/Redis, (6) Execute smoke tests: user auth flow, chat with planner, agent trace display, (7) Document any issues found and create follow-up tasks if needed. BLOCKING: No merge until this passes.",
    "verification": {
      "type": "test_pass",
      "command": "docker-compose up -d && sleep 30 && curl -f http://localhost:3000/health && curl -f http://localhost:8000/health"
    },
    "status": "completed",
    "completed_at": "2025-12-30T22:15:00Z"
  },
  {
    "id": "INTERACT-001",
    "type": "code",
    "priority": "P0",
    "phase": 10,
    "epic": "Epic 13: User Interaction",
    "description": "Interview Response Collection - Enable users to answer Planner clarifying questions",
    "dependencies": [],
    "context_files": [
      "packages/daw-agents/src/daw_agents/agents/planner/taskmaster.py",
      "apps/server/src/daw_server/api/routes.py",
      "apps/web/src/components/plan/ClarificationFlow.tsx"
    ],
    "instruction": "Implement bidirectional interview flow: (1) Backend: Stream interview questions to UI via WebSocket, (2) New endpoint POST /api/workflow/{id}/interview-answer for user responses, (3) Update _interview_node in Taskmaster to pause and wait for user input (async), (4) Interview loop continues until user says 'proceed' or AI has no more questions, (5) Frontend: ClarificationFlow.tsx component displays questions with answer inputs, (6) Support text, multi-choice, and checkbox question types, (7) Progress indicator showing 'Question 2 of 4', (8) 'Skip remaining questions' option with warning, (9) User answers stored in workflow state for Roundtable access.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/agents/planner/test_interview_loop.py && pnpm --filter @daw/web test"
    },
    "status": "completed",
    "completed_at": "2025-12-31T01:32:37.509277Z"
  },
  {
    "id": "INTERACT-002",
    "type": "code",
    "priority": "P0",
    "phase": 10,
    "epic": "Epic 13: User Interaction",
    "description": "PRD Presentation and Display - Show generated PRD in structured format",
    "dependencies": [
      "INTERACT-001"
    ],
    "context_files": [
      "apps/web/src/components/plan/PlanPresentation.tsx",
      "apps/web/src/types/prd.ts"
    ],
    "instruction": "Create PRD display component: (1) PlanPresentation.tsx with structured sections: Overview, User Stories, Tech Specs, Acceptance Criteria, NFRs, Architecture, (2) Expandable/collapsible sections, (3) Roundtable persona feedback displayed (CTO, UX, Security critiques), (4) Complexity scores visualized (heat map or badges), (5) Syntax highlighting for code snippets, (6) Print/Export to PDF button, (7) Backend: PRD data structure includes display metadata, (8) WCAG 2.1 AA accessibility, screen reader compatible.",
    "verification": {
      "type": "test_pass",
      "command": "pnpm --filter @daw/web test && pnpm --filter @daw/web build"
    },
    "status": "completed",
    "completed_at": "2025-12-31T01:32:37.509277Z"
  },
  {
    "id": "INTERACT-003",
    "type": "code",
    "priority": "P0",
    "phase": 10,
    "epic": "Epic 13: User Interaction",
    "description": "PRD Approval Gate - Enable user approval/rejection/modification of PRD",
    "dependencies": [
      "INTERACT-002"
    ],
    "context_files": [
      "apps/server/src/daw_server/api/routes.py",
      "packages/daw-agents/src/daw_agents/workflow/orchestrator.py",
      "apps/web/src/components/plan/ApprovalGate.tsx"
    ],
    "instruction": "Implement PRD approval gate: (1) Backend: New workflow status AWAITING_PRD_APPROVAL, (2) Orchestrator pauses after PRD generation, sets status, (3) New endpoint POST /api/workflow/{id}/prd-review with actions: approve (proceed to tasks), reject (return to interview), modify (regenerate), (4) Frontend: ApprovalGate.tsx with three action buttons, (5) Comment textarea for rejection reason, (6) Modifications form for inline edits, (7) Confirmation modal before approve/reject, (8) WebSocket streams status change when approval needed, (9) Audit: Approval actions logged with timestamp and user.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/workflow/test_prd_approval.py"
    },
    "status": "completed",
    "completed_at": "2025-12-31T01:32:37.509277Z"
  },
  {
    "id": "INTERACT-004",
    "type": "code",
    "priority": "P0",
    "phase": 10,
    "epic": "Epic 13: User Interaction",
    "description": "Task List Review and Approval - Enable user review of decomposed tasks before execution",
    "dependencies": [
      "INTERACT-003"
    ],
    "context_files": [
      "apps/server/src/daw_server/api/routes.py",
      "apps/web/src/components/plan/TaskList.tsx",
      "apps/web/src/components/plan/TaskCard.tsx"
    ],
    "instruction": "Implement task review gate: (1) Backend: New workflow status AWAITING_TASK_APPROVAL, (2) Orchestrator pauses after task decomposition, (3) New endpoint POST /api/workflow/{id}/tasks-review with actions: approve (proceed), reorder, remove, modify, (4) Frontend: TaskList.tsx with hierarchical display (Phase \u2192 Story \u2192 Task), (5) Dependency arrows or badges, (6) Complexity/effort badges per task, (7) Checkbox to remove tasks, inline edit for descriptions, (8) 'Approve and Begin Execution' prominent button, (9) Dependency recalculation when tasks removed.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/workflow/test_task_approval.py && pnpm --filter @daw/web test"
    },
    "status": "completed",
    "completed_at": "2025-12-31T01:32:37.509277Z"
  },
  {
    "id": "INTERACT-005",
    "type": "code",
    "priority": "P1",
    "phase": 10,
    "epic": "Epic 13: User Interaction",
    "description": "Research Display and Evidence - Show research findings that informed PRD",
    "dependencies": [
      "INTERACT-002"
    ],
    "context_files": [
      "apps/web/src/components/plan/ResearchDisplay.tsx"
    ],
    "instruction": "Create research display component: (1) ResearchDisplay.tsx with tabbed interface: Requirements Analysis, Architecture Recommendations, Competitive Analysis, Risk Assessment, Technology Recommendations, (2) Source citations with links, (3) Confidence scores for recommendations, (4) Backend: Research phase captures structured findings attached to workflow state.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web/src/components/plan/ResearchDisplay.tsx"
    },
    "status": "pending"
  },
  {
    "id": "INTERACT-006",
    "type": "code",
    "priority": "P1",
    "phase": 10,
    "epic": "Epic 13: User Interaction",
    "description": "Complexity Analysis Visualization - Display complexity analysis before commitment",
    "dependencies": [
      "INTERACT-002",
      "COMPLEXITY-001"
    ],
    "context_files": [
      "apps/web/src/components/plan/ComplexityAnalysis.tsx"
    ],
    "instruction": "Create complexity visualization: (1) ComplexityAnalysis.tsx component, (2) Cognitive load scores visualized (1-10 scale bars), (3) Dependency graph with risk coloring (low=green, high=red), (4) Recommended model tier per task (info tooltip), (5) Bottleneck warnings highlighted, (6) Overall risk assessment summary, (7) Backend: COMPLEXITY-001 output surfaced to API.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web/src/components/plan/ComplexityAnalysis.tsx"
    },
    "status": "pending"
  },
  {
    "id": "INTERACT-007",
    "type": "code",
    "priority": "P1",
    "phase": 10,
    "epic": "Epic 13: User Interaction",
    "description": "Web Research MCP Integration - Enable Planner to perform web research",
    "dependencies": [
      "CORE-003"
    ],
    "context_files": [
      "packages/daw-mcp/src/daw_mcp/web_research/server.py",
      "packages/daw-agents/src/daw_agents/mcp/rbac.py"
    ],
    "instruction": "Implement web research capability: (1) WebSearchMCPServer in packages/daw-mcp with tools: web_search, fetch_page, summarize_url, (2) Rate limiting and caching, (3) Integration with search API (SerpAPI, Brave, or similar), (4) DocumentationLookupMCPServer with tools: lookup_library_docs, get_api_reference, (5) Integration with Context7 or similar, (6) RBAC policy updated to grant Planner access, (7) Research findings stored in workflow state.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-mcp/tests/web_research/test_server.py"
    },
    "status": "pending"
  },
  {
    "id": "INTERACT-008",
    "type": "code",
    "priority": "P1",
    "phase": 10,
    "epic": "Epic 13: User Interaction",
    "description": "Iterative Planning Refinement - Enable multiple planning iterations",
    "dependencies": [
      "INTERACT-003"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/workflow/orchestrator.py",
      "apps/web/src/components/plan/VersionSelector.tsx"
    ],
    "instruction": "Implement iterative refinement: (1) Backend: Support for 'back to interview' from any planning phase, (2) State preservation when returning to earlier phases, (3) Version history of PRD iterations, (4) Frontend: 'Refine Further' button at each approval gate, (5) Version selector to compare PRD iterations, (6) Diff view showing changes between versions.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/workflow/test_iteration.py"
    },
    "status": "pending"
  },
  {
    "id": "INTERACT-009",
    "type": "code",
    "priority": "P2",
    "phase": 11,
    "epic": "Epic 13: User Interaction",
    "description": "Workflow Progress Dashboard - Visual workflow state machine",
    "dependencies": [
      "INTERACT-001",
      "INTERACT-002",
      "INTERACT-003",
      "INTERACT-004"
    ],
    "context_files": [
      "apps/web/src/components/plan/WorkflowDashboard.tsx"
    ],
    "instruction": "Create workflow dashboard: (1) WorkflowDashboard.tsx with visual state machine (Interview \u2192 Roundtable \u2192 PRD \u2192 Tasks \u2192 Execution \u2192 Validation \u2192 Deploy), (2) Current phase highlighted, (3) Phase descriptions on hover, (4) Time spent in each phase, (5) Phase-specific success criteria checklist.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web/src/components/plan/WorkflowDashboard.tsx"
    },
    "status": "pending"
  },
  {
    "id": "INTERACT-010",
    "type": "code",
    "priority": "P2",
    "phase": 11,
    "epic": "Epic 13: User Interaction",
    "description": "Inline PRD Editing - Direct PRD modification in UI",
    "dependencies": [
      "INTERACT-002",
      "INTERACT-003"
    ],
    "context_files": [
      "apps/web/src/components/plan/PRDEditor.tsx"
    ],
    "instruction": "Implement inline editing: (1) Inline markdown editor for PRD sections, (2) Real-time preview of changes, (3) Backend endpoint to save PRD modifications, (4) Re-validation of modified PRD, (5) 'Save Changes' and 'Discard' buttons.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web/src/components/plan/PRDEditor.tsx"
    },
    "status": "pending"
  },
  {
    "id": "INTERACT-011",
    "type": "code",
    "priority": "P2",
    "phase": 11,
    "epic": "Epic 13: User Interaction",
    "description": "Real-time Persona Collaboration Indicators - Show which AI persona is speaking",
    "dependencies": [
      "INTERACT-002"
    ],
    "context_files": [
      "apps/web/src/components/plan/PersonaIndicator.tsx"
    ],
    "instruction": "Implement persona indicators: (1) Persona avatars with 'speaking' animation, (2) Persona name badge on each message, (3) Backend: WebSocket events include persona_id, (4) 'Planner is thinking...', 'CTO is reviewing...' messages.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web/src/components/plan/PersonaIndicator.tsx"
    },
    "status": "pending"
  },
  {
    "id": "INTERACT-012",
    "type": "code",
    "priority": "P2",
    "phase": 11,
    "epic": "Epic 13: User Interaction",
    "description": "Dependency Resolver MCP Server - Check package dependencies and versions",
    "dependencies": [
      "INTERACT-007"
    ],
    "context_files": [
      "packages/daw-mcp/src/daw_mcp/dependency_resolver/server.py"
    ],
    "instruction": "Implement dependency resolver: (1) DependencyResolverMCPServer with tools: check_package_version, find_conflicts, get_latest_version, (2) Support for npm, PyPI, Cargo registries, (3) Caching for frequent lookups.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-mcp/tests/dependency_resolver/test_server.py"
    },
    "status": "pending"
  },
  {
    "id": "INTEG-001",
    "type": "test",
    "priority": "P0",
    "phase": 12,
    "epic": "Epic 14: Real-World Integration Testing",
    "description": "E2B Sandbox Real Connection Tests - Actual E2B API calls",
    "dependencies": [],
    "context_files": [
      "packages/daw-agents/src/daw_agents/sandbox/e2b.py",
      "tests/integration/test_e2b_real.py"
    ],
    "instruction": "Create integration tests with REAL E2B connections: (1) Create tests/integration/ directory, (2) Add @pytest.mark.integration and @pytest.mark.slow markers to pytest.ini, (3) Load E2B API key from .creds/e2b_api_key.txt, (4) Test real command execution in E2B sandbox, (5) Test real file operations, (6) Test sandbox lifecycle (start/stop), (7) NO MOCKS - actual E2B API calls. Tests should be excluded from default pytest runs.",
    "verification": {
      "type": "test_pass",
      "command": "pytest tests/integration/test_e2b_real.py -m 'integration' -v"
    },
    "estimated_hours": 3,
    "status": "completed",
    "completed_at": "2025-12-30T23:00:00Z"
  },
  {
    "id": "INTEG-002",
    "type": "test",
    "priority": "P0",
    "phase": 12,
    "epic": "Epic 14: Real-World Integration Testing",
    "description": "Neo4j VPS Real Connection Tests - Hostinger VPS integration",
    "dependencies": [],
    "context_files": [
      "packages/daw-agents/src/daw_agents/memory/neo4j.py",
      "tests/integration/test_neo4j_real.py"
    ],
    "instruction": "Create integration tests with REAL Neo4j on Hostinger VPS: (1) Connect to bolt://72.60.204.156:7687, (2) Load credentials from .creds/neo4j_vps.txt, (3) Test create_node with real data, (4) Test query with real Cypher, (5) Test create_relationship, (6) Test Experience Logger integration, (7) Cleanup test data after each test (no pollution), (8) NO MOCKS - actual Neo4j calls.",
    "verification": {
      "type": "test_pass",
      "command": "pytest tests/integration/test_neo4j_real.py -m 'integration' -v"
    },
    "estimated_hours": 3,
    "status": "completed",
    "completed_at": "2025-12-30T23:00:00Z"
  },
  {
    "id": "INTEG-003",
    "type": "test",
    "priority": "P0",
    "phase": 12,
    "epic": "Epic 14: Real-World Integration Testing",
    "description": "E2B \u2192 Neo4j End-to-End Test - Full round-trip validation",
    "dependencies": [
      "INTEG-001",
      "INTEG-002"
    ],
    "context_files": [
      "tests/integration/test_e2b_neo4j_e2e.py"
    ],
    "instruction": "Create E2E test validating E2B can communicate with Neo4j VPS: (1) Start real E2B sandbox, (2) Write Python script inside sandbox that connects to Neo4j VPS (bolt://72.60.204.156:7687), (3) Script creates test node in Neo4j, (4) Verify node exists by querying Neo4j directly from test, (5) Cleanup test data, (6) This validates network connectivity from E2B cloud to Hostinger VPS.",
    "verification": {
      "type": "test_pass",
      "command": "pytest tests/integration/test_e2b_neo4j_e2e.py -m 'integration' -v"
    },
    "estimated_hours": 4,
    "status": "completed",
    "completed_at": "2025-12-30T23:15:00Z"
  },
  {
    "id": "FUNC-001",
    "type": "test",
    "priority": "P0",
    "phase": 13,
    "epic": "Epic 14: Real-World Integration Testing",
    "description": "Dogfood Test - Build Calculator with DAW",
    "dependencies": [
      "ORCHESTRATOR-001",
      "INTEG-003"
    ],
    "context_files": [
      "tests/functional/test_dogfood_calculator.py",
      "eval/benchmarks/calculator/"
    ],
    "instruction": "Create functional test that uses DAW to build a calculator: (1) Submit PRD 'Build a calculator with add, subtract, multiply, divide', (2) Invoke Planner Agent to decompose tasks, (3) Invoke Executor Agent to generate code, (4) Invoke Validator Agent to run tests, (5) Verify generated calculator actually works (2+2=4), (6) Full agent pipeline validation, (7) Store results in eval_results/. This is the 'dogfood' test from test strategy.",
    "verification": {
      "type": "test_pass",
      "command": "pytest tests/functional/test_dogfood_calculator.py -v"
    },
    "estimated_hours": 6,
    "status": "completed",
    "completed_at": "2025-12-30T23:30:00Z"
  },
  {
    "id": "FUNC-002",
    "type": "test",
    "priority": "P1",
    "phase": 13,
    "epic": "Epic 14: Real-World Integration Testing",
    "description": "Dogfood Test - Build Settings Page with DAW",
    "dependencies": [
      "FUNC-001",
      "FRONTEND-002"
    ],
    "context_files": [
      "tests/functional/test_dogfood_settings.py"
    ],
    "instruction": "Create functional test that uses DAW to build a settings page FOR DAW itself: (1) Submit PRD 'Add settings page to DAW dashboard with theme toggle', (2) Planner generates frontend tasks (React/TypeScript), (3) Executor generates component code, (4) Validator verifies component compiles and tests pass, (5) Generated component should integrate with existing dashboard, (6) Visual regression test for new component.",
    "verification": {
      "type": "test_pass",
      "command": "pytest tests/functional/test_dogfood_settings.py -v"
    },
    "estimated_hours": 8,
    "status": "completed",
    "completed_at": "2025-12-30T23:45:00Z"
  },
  {
    "id": "FUNC-003",
    "type": "infra",
    "priority": "P0",
    "phase": 12,
    "epic": "Epic 14: Real-World Integration Testing",
    "description": "Nightly Integration CI Workflow - Automated regression with real services",
    "dependencies": [
      "INTEG-001",
      "INTEG-002"
    ],
    "context_files": [
      ".github/workflows/integration-nightly.yml"
    ],
    "instruction": "Create GitHub Actions workflow for nightly integration tests: (1) Runs at 3 AM UTC daily, (2) Uses real E2B API key from secrets, (3) Connects to real Neo4j VPS, (4) Runs all @pytest.mark.integration tests, (5) Stores results in eval_results/, (6) Compares against baseline for regression detection, (7) Sends Slack notification on failure, (8) Does NOT run on PR (too expensive/slow).",
    "verification": {
      "type": "file_exists",
      "path": ".github/workflows/integration-nightly.yml"
    },
    "estimated_hours": 4,
    "status": "completed",
    "completed_at": "2025-12-30T23:15:00Z"
  },
  {
    "id": "KANBAN-001",
    "type": "code",
    "priority": "P0",
    "phase": 14,
    "epic": "Epic 15: Kanban Board & Real-Time Visualization",
    "scope": "MVP",
    "description": "Core Kanban Board Component - Task visualization with column-based workflow",
    "dependencies": [
      "STREAMING-001",
      "FRONTEND-001"
    ],
    "context_files": [
      "apps/web/src/components/kanban/KanbanBoard.tsx",
      "apps/web/src/components/kanban/TaskCard.tsx",
      "apps/web/src/components/kanban/ColumnHeader.tsx"
    ],
    "instruction": "Implement Kanban board: (1) KanbanBoard.tsx with 6 columns: Backlog, Planning, Coding, Validating, Deploying, Done, (2) TaskCard.tsx with ID, description, status, assignee, (3) Real-time updates via WebSocket subscription, (4) Column task counts, (5) GET /api/workflow/{id}/kanban endpoint, (6) PATCH /api/workflow/{id}/kanban/{taskId} for moves, (7) Two-way sync: UI <-> tasks.json, (8) Unit tests for board state.",
    "verification": {
      "type": "test_pass",
      "command": "pnpm --filter @daw/web test -- --grep 'KanbanBoard'"
    },
    "estimated_hours": 12,
    "status": "completed",
    "completed_at": "2025-12-31T01:32:37.509277Z"
  },
  {
    "id": "KANBAN-002",
    "type": "code",
    "priority": "P0",
    "phase": 14,
    "epic": "Epic 15: Kanban Board & Real-Time Visualization",
    "scope": "MVP",
    "description": "Task Card Details Panel - Expandable task information view",
    "dependencies": [
      "KANBAN-001"
    ],
    "context_files": [
      "apps/web/src/components/kanban/TaskDetailPanel.tsx"
    ],
    "instruction": "Implement task detail panel: (1) TaskDetailPanel.tsx slide-out panel, (2) Shows description, dependencies, assigned agent, artifacts, (3) Activity timeline with status changes and commits, (4) Link to agent trace view, (5) Unit tests for panel rendering.",
    "verification": {
      "type": "test_pass",
      "command": "pnpm --filter @daw/web test -- --grep 'TaskDetailPanel'"
    },
    "estimated_hours": 6,
    "status": "completed",
    "completed_at": "2025-12-31T01:32:37.509277Z"
  },
  {
    "id": "KANBAN-003",
    "type": "code",
    "priority": "P0",
    "phase": 14,
    "epic": "Epic 15: Kanban Board & Real-Time Visualization",
    "scope": "MVP",
    "description": "Live Status Streaming to Kanban - Real-time WebSocket updates",
    "dependencies": [
      "KANBAN-001",
      "STREAMING-001"
    ],
    "context_files": [
      "apps/web/src/hooks/useKanban.ts",
      "packages/daw-agents/src/daw_agents/api/websocket.py"
    ],
    "instruction": "Implement live streaming: (1) useKanban hook with WebSocket subscription, (2) Backend emits kanban_update events on task status change, (3) Optimistic updates with rollback on failure, (4) Connection status indicator, (5) Auto-reconnect on disconnect, (6) WebSocket event handling tests.",
    "verification": {
      "type": "test_pass",
      "command": "pnpm --filter @daw/web test -- --grep 'useKanban'"
    },
    "estimated_hours": 6,
    "status": "completed",
    "completed_at": "2025-12-31T01:32:37.509277Z"
  },
  {
    "id": "KANBAN-004",
    "type": "code",
    "priority": "P1",
    "phase": 15,
    "epic": "Epic 15: Kanban Board & Real-Time Visualization",
    "scope": "Production",
    "description": "Drag-and-Drop Task Prioritization - Manual task reordering",
    "dependencies": [
      "KANBAN-001"
    ],
    "context_files": [
      "apps/web/src/components/kanban/DraggableCard.tsx"
    ],
    "instruction": "Implement drag-drop: (1) @dnd-kit integration, (2) Visual feedback during drag, (3) Priority update endpoint, (4) Dependency validation (can't move before dependencies), (5) Orchestrator respects user priority ordering.",
    "verification": {
      "type": "test_pass",
      "command": "pnpm --filter @daw/web test -- --grep 'Draggable'"
    },
    "estimated_hours": 8,
    "status": "pending"
  },
  {
    "id": "KANBAN-005",
    "type": "code",
    "priority": "P1",
    "phase": 15,
    "epic": "Epic 15: Kanban Board & Real-Time Visualization",
    "scope": "Production",
    "description": "Agent Assignment Display - Show which agent is working on tasks",
    "dependencies": [
      "KANBAN-001"
    ],
    "context_files": [
      "apps/web/src/components/kanban/AgentAvatar.tsx"
    ],
    "instruction": "Implement agent display: (1) Agent avatar on task cards, (2) Agent status indicator (working, idle, error), (3) Click avatar -> agent detail popover, (4) Backend: agent assignment tracking.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web/src/components/kanban/AgentAvatar.tsx"
    },
    "estimated_hours": 5,
    "status": "pending"
  },
  {
    "id": "KANBAN-006",
    "type": "code",
    "priority": "P1",
    "phase": 15,
    "epic": "Epic 15: Kanban Board & Real-Time Visualization",
    "scope": "Production",
    "description": "Metrics Dashboard - Workflow analytics and cost tracking",
    "dependencies": [
      "KANBAN-001"
    ],
    "context_files": [
      "apps/web/src/components/dashboard/MetricsDashboard.tsx"
    ],
    "instruction": "Implement metrics: (1) MetricsDashboard.tsx component, (2) Tasks completed, avg time per task, error rate, (3) Token usage, cost accumulation, (4) Model distribution charts, (5) Progress over time visualization.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web/src/components/dashboard/MetricsDashboard.tsx"
    },
    "estimated_hours": 8,
    "status": "pending"
  },
  {
    "id": "KANBAN-007",
    "type": "code",
    "priority": "P2",
    "phase": 16,
    "epic": "Epic 15: Kanban Board & Real-Time Visualization",
    "scope": "Future",
    "description": "Multi-Workflow Board - View multiple workflows on single board",
    "dependencies": [
      "KANBAN-001"
    ],
    "context_files": [],
    "instruction": "Implement multi-workflow view: (1) Workflow selector dropdown, (2) Split view option, (3) Cross-workflow dependency visualization.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web/src/components/kanban/MultiWorkflowBoard.tsx"
    },
    "status": "pending"
  },
  {
    "id": "KANBAN-008",
    "type": "code",
    "priority": "P2",
    "phase": 16,
    "epic": "Epic 15: Kanban Board & Real-Time Visualization",
    "scope": "Future",
    "description": "Custom Column Configuration - User-defined workflow stages",
    "dependencies": [
      "KANBAN-001"
    ],
    "context_files": [],
    "instruction": "Implement custom columns: (1) Column configuration modal, (2) Persist column settings per user, (3) Default templates for common workflows.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web/src/components/kanban/ColumnConfig.tsx"
    },
    "status": "pending"
  },
  {
    "id": "KANBAN-009",
    "type": "code",
    "priority": "P2",
    "phase": 16,
    "epic": "Epic 15: Kanban Board & Real-Time Visualization",
    "scope": "Future",
    "description": "Swimlane Views - Group tasks by feature, priority, or agent",
    "dependencies": [
      "KANBAN-001"
    ],
    "context_files": [],
    "instruction": "Implement swimlanes: (1) Group by feature, priority, or agent, (2) Collapsible swimlane rows, (3) Swimlane totals.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web/src/components/kanban/SwimLaneView.tsx"
    },
    "status": "pending"
  },
  {
    "id": "MDH-001",
    "type": "code",
    "priority": "P1",
    "phase": 17,
    "epic": "Epic 16: Monitor-Diagnose-Heal Loop",
    "scope": "Production",
    "description": "Monitor Node Integration - Post-deployment health monitoring",
    "dependencies": [
      "ORCHESTRATOR-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/orchestrator/orchestrator.py"
    ],
    "instruction": "Implement monitor node: (1) MONITORING status in OrchestratorStatus enum, (2) _monitor_node() in Orchestrator, (3) Health check logic for deployed code, (4) Integration with Sentry/Datadog hooks, (5) Anomaly detection thresholds, (6) Tests for monitoring state transitions.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/orchestrator/test_monitor_node.py -v"
    },
    "estimated_hours": 8,
    "status": "pending"
  },
  {
    "id": "MDH-002",
    "type": "code",
    "priority": "P1",
    "phase": 17,
    "epic": "Epic 16: Monitor-Diagnose-Heal Loop",
    "scope": "Production",
    "description": "Diagnose Node Implementation - Automated error analysis",
    "dependencies": [
      "MDH-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/orchestrator/orchestrator.py"
    ],
    "instruction": "Implement diagnose node: (1) DIAGNOSING status, (2) _diagnose_node() in Orchestrator, (3) Error classification (fixable vs. critical), (4) Root cause analysis using error knowledge graph, (5) Query Neo4j for similar past errors, (6) Connect to Healer agent, (7) Diagnosis accuracy tests.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/orchestrator/test_diagnose_node.py -v"
    },
    "estimated_hours": 8,
    "status": "pending"
  },
  {
    "id": "MDH-003",
    "type": "code",
    "priority": "P1",
    "phase": 17,
    "epic": "Epic 16: Monitor-Diagnose-Heal Loop",
    "scope": "Production",
    "description": "Heal Node Implementation - Automated fix application",
    "dependencies": [
      "MDH-002"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/orchestrator/orchestrator.py",
      "packages/daw-agents/src/daw_agents/agents/healer/"
    ],
    "instruction": "Implement heal node: (1) HEALING status, (2) _heal_node() in Orchestrator, (3) Wire existing Healer agent into workflow, (4) Auto-retry up to 3x before escalation, (5) Create reproduction test case (Red), (6) Apply fix (Green), (7) Push to staging branch, (8) Healing success rate tests.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/orchestrator/test_heal_node.py -v"
    },
    "estimated_hours": 8,
    "status": "pending"
  },
  {
    "id": "MDH-004",
    "type": "code",
    "priority": "P1",
    "phase": 17,
    "epic": "Epic 16: Monitor-Diagnose-Heal Loop",
    "scope": "Production",
    "description": "Escalation & Human Override - Unfixable error handling",
    "dependencies": [
      "MDH-003"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/orchestrator/orchestrator.py",
      "apps/web/src/components/dashboard/EscalationAlert.tsx"
    ],
    "instruction": "Implement escalation: (1) ESCALATING status, (2) Alert generation with full context, (3) Human approval endpoint, (4) Frontend: EscalationAlert component, (5) 'Override and Continue' or 'Pause' buttons, (6) Slack/email webhook integration.",
    "verification": {
      "type": "file_exists",
      "path": "apps/web/src/components/dashboard/EscalationAlert.tsx"
    },
    "estimated_hours": 6,
    "status": "pending"
  },
  {
    "id": "MDH-005",
    "type": "code",
    "priority": "P2",
    "phase": 18,
    "epic": "Epic 16: Monitor-Diagnose-Heal Loop",
    "scope": "Future",
    "description": "Sentinel Agent - Risk scanning and interception",
    "dependencies": [
      "MDH-001",
      "CORE-003"
    ],
    "context_files": [
      "packages/daw-mcp/src/daw_mcp/servers/sentinel.py"
    ],
    "instruction": "Implement Sentinel: (1) SentinelAgent class running parallel to Orchestrator, (2) Intercepts dangerous commands (DROP, rm -rf, sudo), (3) Requires human approval for intercepted ops, (4) SentinelMCPServer with tools: scan_command, request_approval, log_interception.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-mcp/tests/sentinel/test_server.py -v"
    },
    "status": "pending"
  },
  {
    "id": "MDH-006",
    "type": "code",
    "priority": "P2",
    "phase": 18,
    "epic": "Epic 16: Monitor-Diagnose-Heal Loop",
    "scope": "Future",
    "description": "Predictive Issue Detection - Proactive problem identification",
    "dependencies": [
      "MDH-001",
      "EVOLVE-001"
    ],
    "context_files": [],
    "instruction": "Implement prediction: (1) Pattern analysis from historical data, (2) Predict issues before they occur, (3) Proactive alerts.",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-agents/src/daw_agents/orchestrator/predictor.py"
    },
    "status": "pending"
  },
  {
    "id": "MDH-007",
    "type": "code",
    "priority": "P2",
    "phase": 18,
    "epic": "Epic 16: Monitor-Diagnose-Heal Loop",
    "scope": "Future",
    "description": "Auto-Rollback Capability - Automatic recovery to last good state",
    "dependencies": [
      "MDH-003"
    ],
    "context_files": [],
    "instruction": "Implement rollback: (1) Track deployment checkpoints, (2) Auto-rollback on critical failure, (3) Notify user of rollback.",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-agents/src/daw_agents/orchestrator/rollback.py"
    },
    "status": "pending"
  },
  {
    "id": "EVOLVE-003",
    "type": "code",
    "priority": "P1",
    "phase": 17,
    "epic": "Epic 17: Self-Evolution & Learning",
    "scope": "Production",
    "description": "Skill Extraction Library - Extract reusable patterns from successes",
    "dependencies": [
      "EVOLVE-001",
      "EVOLVE-002"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/evolution/skill_extractor.py"
    ],
    "instruction": "Implement skill extraction: (1) SkillExtractor class, (2) Analyze successful task completions, (3) Extract code patterns as reusable 'skills', (4) Store skills in Neo4j with success_rate, (5) Retrieve skills for similar future tasks, (6) Voyager-style skill library pattern, (7) Skill extraction accuracy tests.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/evolution/test_skill_extractor.py -v"
    },
    "estimated_hours": 12,
    "status": "pending"
  },
  {
    "id": "EVOLVE-004",
    "type": "code",
    "priority": "P1",
    "phase": 17,
    "epic": "Epic 17: Self-Evolution & Learning",
    "scope": "Production",
    "description": "Model Performance Analytics - Track model effectiveness by task type",
    "dependencies": [
      "EVOLVE-001",
      "MODEL-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/evolution/model_analytics.py",
      "apps/web/src/components/dashboard/ModelAnalytics.tsx"
    ],
    "instruction": "Implement analytics: (1) Performance metrics per model per task type, (2) Success rate, latency, cost analysis, (3) Automatic model recommendation updates, (4) Frontend: ModelAnalytics dashboard, (5) Helicone data aggregation.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/evolution/test_model_analytics.py -v"
    },
    "estimated_hours": 10,
    "status": "pending"
  },
  {
    "id": "EVOLVE-005",
    "type": "code",
    "priority": "P2",
    "phase": 18,
    "epic": "Epic 17: Self-Evolution & Learning",
    "scope": "Future",
    "description": "Prompt Optimization (DSPy) - Automatic prompt improvement",
    "dependencies": [
      "EVOLVE-003",
      "EVOLVE-004"
    ],
    "context_files": [],
    "instruction": "Implement DSPy-style prompt optimization: (1) Track prompt effectiveness, (2) Suggest prompt improvements, (3) A/B test prompt variations.",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-agents/src/daw_agents/evolution/prompt_optimizer.py"
    },
    "status": "pending"
  },
  {
    "id": "EVOLVE-006",
    "type": "code",
    "priority": "P2",
    "phase": 18,
    "epic": "Epic 17: Self-Evolution & Learning",
    "scope": "Future",
    "description": "A/B Testing Infrastructure - Statistical experiment framework",
    "dependencies": [
      "EVOLVE-005"
    ],
    "context_files": [],
    "instruction": "Implement A/B testing: (1) Experiment definition, (2) Traffic splitting, (3) Statistical significance calculation, (4) Winner declaration.",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-agents/src/daw_agents/evolution/ab_testing.py"
    },
    "status": "pending"
  },
  {
    "id": "EVOLVE-007",
    "type": "code",
    "priority": "P2",
    "phase": 18,
    "epic": "Epic 17: Self-Evolution & Learning",
    "scope": "Future",
    "description": "Constitutional Safety Constraints - Safety guardrails for self-modification",
    "dependencies": [
      "EVOLVE-005"
    ],
    "context_files": [],
    "instruction": "Implement safety: (1) RLAIF constraints for self-modification, (2) Bounded evolution limits, (3) Human approval for significant changes.",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-agents/src/daw_agents/evolution/constitutional.py"
    },
    "status": "pending"
  },
  {
    "id": "DRIVER-001",
    "type": "code",
    "priority": "P1",
    "phase": 17,
    "epic": "Epic 18: Multi-Model Driver Support",
    "scope": "Production",
    "description": "Model Driver Abstraction Layer - Hot-swappable model configuration",
    "dependencies": [
      "MODEL-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/models/drivers/base.py",
      "packages/daw-agents/src/daw_agents/models/drivers/claude.py",
      "packages/daw-agents/src/daw_agents/models/drivers/openai.py",
      "packages/daw-agents/src/daw_agents/models/drivers/gemini.py"
    ],
    "instruction": "Implement driver abstraction: (1) ModelDriver abstract interface, (2) ClaudeDriver, OpenAIDriver, GeminiDriver, LocalDriver implementations, (3) Config via config.yaml use_driver setting, (4) Task formatting per driver requirements, (5) Unified response parsing, (6) Automatic fallback on driver failure, (7) Driver switching tests.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/models/test_drivers.py -v"
    },
    "estimated_hours": 10,
    "status": "pending"
  },
  {
    "id": "DRIVER-002",
    "type": "code",
    "priority": "P1",
    "phase": 17,
    "epic": "Epic 18: Multi-Model Driver Support",
    "scope": "Production",
    "description": "Model Driver MCP Server - Expose model config via MCP",
    "dependencies": [
      "DRIVER-001",
      "CORE-003"
    ],
    "context_files": [
      "packages/daw-mcp/src/daw_mcp/servers/model_driver.py"
    ],
    "instruction": "Implement MCP server: (1) ModelDriverMCPServer in packages/daw-mcp/, (2) Tools: list_models, get_model_config, estimate_cost, recommend_model, (3) Query from Planner for recommendations, (4) MCP server unit tests.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-mcp/tests/model_driver/test_server.py -v"
    },
    "estimated_hours": 6,
    "status": "pending"
  },
  {
    "id": "DRIVER-003",
    "type": "code",
    "priority": "P1",
    "phase": 17,
    "epic": "Epic 18: Multi-Model Driver Support",
    "scope": "Production",
    "description": "Cost Optimization Router - Intelligent cost/capability routing",
    "dependencies": [
      "DRIVER-001",
      "MODEL-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/models/cost_router.py"
    ],
    "instruction": "Implement cost router: (1) Cost-aware routing in ModelRouter, (2) Task complexity -> model tier mapping, (3) Budget constraints respected, (4) Frontend: cost projection display, (5) Cost optimization accuracy tests.",
    "verification": {
      "type": "test_pass",
      "command": "pytest packages/daw-agents/tests/models/test_cost_router.py -v"
    },
    "estimated_hours": 8,
    "status": "pending"
  },
  {
    "id": "DRIVER-004",
    "type": "code",
    "priority": "P2",
    "phase": 18,
    "epic": "Epic 18: Multi-Model Driver Support",
    "scope": "Future",
    "description": "Local Model Support - Ollama/LM Studio integration",
    "dependencies": [
      "DRIVER-001"
    ],
    "context_files": [
      "packages/daw-agents/src/daw_agents/models/drivers/local.py"
    ],
    "instruction": "Implement local models: (1) LocalDriver for Ollama/LM Studio, (2) Model discovery and configuration, (3) Performance benchmarking.",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-agents/src/daw_agents/models/drivers/local.py"
    },
    "status": "pending"
  },
  {
    "id": "DRIVER-005",
    "type": "code",
    "priority": "P2",
    "phase": 18,
    "epic": "Epic 18: Multi-Model Driver Support",
    "scope": "Future",
    "description": "Model Ensemble Voting - Multi-model consensus for critical decisions",
    "dependencies": [
      "DRIVER-001"
    ],
    "context_files": [],
    "instruction": "Implement ensemble: (1) Multiple models vote on critical decisions, (2) Consensus threshold configuration, (3) Disagreement escalation to human.",
    "verification": {
      "type": "file_exists",
      "path": "packages/daw-agents/src/daw_agents/models/ensemble.py"
    },
    "status": "pending"
  }
]
